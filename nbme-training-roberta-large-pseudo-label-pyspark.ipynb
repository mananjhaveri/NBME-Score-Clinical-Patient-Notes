{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"f4","metadata":{}},{"cell_type":"code","source":"!pip install -q pyspark","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:11:51.400816Z","iopub.execute_input":"2022-03-15T11:11:51.401315Z","iopub.status.idle":"2022-03-15T11:12:32.399251Z","shell.execute_reply.started":"2022-03-15T11:11:51.401222Z","shell.execute_reply":"2022-03-15T11:12:32.398433Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1644226678252,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"ZJMQe7lZgIvF","execution":{"iopub.status.busy":"2022-03-15T11:12:32.402000Z","iopub.execute_input":"2022-03-15T11:12:32.402286Z","iopub.status.idle":"2022-03-15T11:12:32.407940Z","shell.execute_reply.started":"2022-03-15T11:12:32.402250Z","shell.execute_reply":"2022-03-15T11:12:32.407321Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import gc\nimport os\nimport re\nimport ast\nimport time\nimport copy\nimport torch\nimport json\nimport wandb\nimport joblib\nimport random\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport transformers\nfrom torch import nn \nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F \nfrom sklearn import metrics, model_selection\nfrom torch.utils.data import Sampler, Dataset, DataLoader\nfrom pyspark.sql import SparkSession\n\ngc.enable()","metadata":{"executionInfo":{"elapsed":6954,"status":"ok","timestamp":1644226685194,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"VWg1p0mmiFjQ","execution":{"iopub.status.busy":"2022-03-15T11:12:32.410887Z","iopub.execute_input":"2022-03-15T11:12:32.411283Z","iopub.status.idle":"2022-03-15T11:12:35.524653Z","shell.execute_reply.started":"2022-03-15T11:12:32.411255Z","shell.execute_reply":"2022-03-15T11:12:35.523867Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"config = dict(\n    # basic\n    seed = 3407,\n    num_jobs=1,\n    num_labels=2,\n    num_folds=5,\n    \n    # model info\n    tokenizer_path = '../input/robertalarge',\n    model_checkpoint = '../input/robertalarge', \n    resume_training_checkpoint = None,\n    device = 'cuda' if torch.cuda.is_available() else 'cpu',\n    \n    # trining paramters\n    learning_rate = 1e-5,\n    weight_decay = 1e-2,\n    max_length = 420,\n    train_batch_size = 4,\n    valid_batch_size = 8,\n    epochs_to_train = 4,\n    total_epochs = 5,\n    grad_acc_steps = 4,\n    \n    # for this notebook\n    report_to = 'wandb',\n    output_dir = '',\n    fold_to_train = [4],\n    title = 'roberta-large-multidrop-pseudolabel',\n    debug = False,\n    platform = 'kaggle', # kaggle, colab\n    inference_only = False,\n)\n\ntitle = config['title']\n\nif config['platform'] == 'colab':\n    config['output_dir'] = f'../output/{title}/'\n    base_path = 'drive/MyDrive/NBME'\n    os.chdir(base_path + '/src')","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1644226685194,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"YFVF6vYGiFn3","execution":{"iopub.status.busy":"2022-03-15T11:12:35.527032Z","iopub.execute_input":"2022-03-15T11:12:35.527297Z","iopub.status.idle":"2022-03-15T11:12:35.574773Z","shell.execute_reply.started":"2022-03-15T11:12:35.527261Z","shell.execute_reply":"2022-03-15T11:12:35.573571Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"spark = SparkSession \\\n    .builder \\\n    .appName(\"nbme_app\") \\\n    .getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:12:35.576552Z","iopub.execute_input":"2022-03-15T11:12:35.576997Z","iopub.status.idle":"2022-03-15T11:12:42.171274Z","shell.execute_reply.started":"2022-03-15T11:12:35.576961Z","shell.execute_reply":"2022-03-15T11:12:42.170449Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"WARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\nUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n22/03/15 11:12:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"5rd0fSqf9PEZ","executionInfo":{"status":"ok","timestamp":1644226685195,"user_tz":-330,"elapsed":10,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"}},"outputId":"697fc48d-e5c2-49da-bb93-2c94827045f8","execution":{"iopub.status.busy":"2022-03-15T11:12:42.172665Z","iopub.execute_input":"2022-03-15T11:12:42.172924Z","iopub.status.idle":"2022-03-15T11:12:42.920408Z","shell.execute_reply.started":"2022-03-15T11:12:42.172887Z","shell.execute_reply":"2022-03-15T11:12:42.919360Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Tue Mar 15 11:12:42 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   32C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"def setup_wandb(name):\n    if config['platform'] == 'kaggle':\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        secret_value_0 = user_secrets.get_secret(\"wandb_api_key\")\n    else:\n        secret_value_0 = '...' \n\n    wandb.login(key=secret_value_0)\n    wandb.init(\n        project='nbme',\n        entity=\"devanshu125\",\n        name=name,\n        save_code=True,\n    )\n    wandb.config = config","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644226685195,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"9jk74OntiFqR","execution":{"iopub.status.busy":"2022-03-15T11:12:42.921991Z","iopub.execute_input":"2022-03-15T11:12:42.922288Z","iopub.status.idle":"2022-03-15T11:12:42.931308Z","shell.execute_reply.started":"2022-03-15T11:12:42.922245Z","shell.execute_reply":"2022-03-15T11:12:42.930529Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def create_folds(data):\n    \n    data['kfold'] = -1\n    data['for_stratify'] = data['case_num'].astype(str) + '_' + data['feature_num'].astype(str)\n\n    kf = model_selection.StratifiedKFold(n_splits=config['num_folds'], shuffle=True, random_state=config['seed'])\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data['for_stratify'])):\n        data.loc[v_, 'kfold'] = f\n    \n    data.drop(['for_stratify'], axis=1, inplace=True)\n\n    return data","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644226685195,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"L-93swEXm7w4","execution":{"iopub.status.busy":"2022-03-15T11:12:42.932861Z","iopub.execute_input":"2022-03-15T11:12:42.933116Z","iopub.status.idle":"2022-03-15T11:12:42.941516Z","shell.execute_reply.started":"2022-03-15T11:12:42.933083Z","shell.execute_reply":"2022-03-15T11:12:42.940866Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def loc_list_to_ints(loc_list):\n    to_return = []\n    for loc_str in loc_list:\n        loc_strs = loc_str.split(\";\")\n        for loc in loc_strs:\n            start, end = loc.split()\n            to_return.append((int(start), int(end)))\n    return to_return\n\n\ndef tokenize_and_add_labels(tokenizer, example):\n    tokenized_inputs = tokenizer(\n        example[\"feature_text\"],\n        example[\"pn_history\"],\n        truncation=\"only_second\",\n        max_length=config['max_length'],\n        padding=\"max_length\",\n        return_offsets_mapping=True\n    )\n    labels = [0.0] * len(tokenized_inputs[\"input_ids\"])\n    tokenized_inputs[\"location_int\"] = loc_list_to_ints(example[\"location\"])\n    tokenized_inputs[\"sequence_ids\"] = tokenized_inputs.sequence_ids()\n    \n    for idx, (seq_id, offsets) in enumerate(zip(tokenized_inputs[\"sequence_ids\"], tokenized_inputs[\"offset_mapping\"])):\n        if seq_id is None or seq_id == 0:\n            labels[idx] = -100\n            continue\n        exit = False\n        token_start, token_end = offsets\n        for feature_start, feature_end in tokenized_inputs[\"location_int\"]:\n            if exit:\n                break\n            if token_start >= feature_start and token_end <= feature_end:\n                labels[idx] = 1.0\n                exit = True\n    tokenized_inputs[\"labels\"] = labels\n    \n    return tokenized_inputs","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644226685196,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"AqZMW552pZym","execution":{"iopub.status.busy":"2022-03-15T11:12:42.942992Z","iopub.execute_input":"2022-03-15T11:12:42.943286Z","iopub.status.idle":"2022-03-15T11:12:42.957175Z","shell.execute_reply.started":"2022-03-15T11:12:42.943252Z","shell.execute_reply":"2022-03-15T11:12:42.956322Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class NBMEData(torch.utils.data.Dataset):\n    def __init__(self, data, tokenizer):\n        self.data = data\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        example = self.data.loc[idx]\n        tokenized = tokenize_and_add_labels(self.tokenizer, example)\n        \n        input_ids = np.array(tokenized[\"input_ids\"])\n        attention_mask = np.array(tokenized[\"attention_mask\"])\n        labels = np.array(tokenized[\"labels\"])\n        offset_mapping = np.array(tokenized[\"offset_mapping\"])\n        sequence_ids = np.array(tokenized[\"sequence_ids\"]).astype(\"float16\")\n        \n        return {\n            'input_ids': input_ids, \n            'attention_mask': attention_mask, \n            'targets': labels, \n            'offset_mapping': offset_mapping, \n            'sequence_ids': sequence_ids,\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:12:42.960510Z","iopub.execute_input":"2022-03-15T11:12:42.960728Z","iopub.status.idle":"2022-03-15T11:12:42.970850Z","shell.execute_reply.started":"2022-03-15T11:12:42.960703Z","shell.execute_reply":"2022-03-15T11:12:42.970058Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class NBMEModel(nn.Module):\n    def __init__(self, num_labels, path=None):\n        super().__init__()\n        \n        layer_norm_eps: float = 1e-6\n        \n        self.path = path\n        self.num_labels = num_labels\n        self.config = transformers.AutoConfig.from_pretrained(config['model_checkpoint'])\n\n        self.config.update(\n            {\n                \"layer_norm_eps\": layer_norm_eps,\n            }\n        )\n        self.transformer = transformers.AutoModel.from_pretrained(config['model_checkpoint'], config=self.config)\n        self.dropout = nn.Dropout(0.1)\n        \n        self.dropout1 = nn.Dropout(0.1)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.3)\n        self.dropout4 = nn.Dropout(0.4)\n        self.dropout5 = nn.Dropout(0.5)\n        \n        self.output = nn.Linear(self.config.hidden_size, 1)\n        \n        if self.path is not None:\n            self.load_state_dict(torch.load(self.path)['model'])\n    \n    def forward(self, data):\n        \n        ids = data['input_ids']\n        mask = data['attention_mask']\n        try:\n            target = data['targets']\n        except:\n            target = None\n\n        transformer_out = self.transformer(ids, mask)\n        sequence_output = transformer_out[0]\n        sequence_output = self.dropout(sequence_output)\n    \n        logits1 = self.output(self.dropout1(sequence_output))\n        logits2 = self.output(self.dropout2(sequence_output))\n        logits3 = self.output(self.dropout3(sequence_output))\n        logits4 = self.output(self.dropout4(sequence_output))\n        logits5 = self.output(self.dropout5(sequence_output))\n\n        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n        ret = {\n            'logits': torch.sigmoid(logits), \n        }\n        \n        loss = 0\n\n        if target is not None:\n            loss1 = self.get_loss(logits1, target)\n            loss2 = self.get_loss(logits2, target)\n            loss3 = self.get_loss(logits3, target)\n            loss4 = self.get_loss(logits4, target)\n            loss5 = self.get_loss(logits5, target)\n            loss = (loss1 + loss2 + loss3 + loss4 + loss5) / 5\n            ret['loss'] = loss\n            ret['target'] = target\n\n        return ret\n\n        \n    def get_optimizer(self, learning_rate, weigth_decay):\n        optimizer = torch.optim.AdamW(\n            self.parameters(), \n            lr=learning_rate, \n            weight_decay=weigth_decay,\n        )\n        if self.path is not None:\n            optimizer.load_state_dict(torch.load(self.path)['optimizer'])\n        \n        return optimizer\n            \n    def get_scheduler(self, optimizer, num_warmup_steps, num_training_steps):\n        scheduler = transformers.get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=num_warmup_steps,\n            num_training_steps=num_training_steps,\n        )\n        if self.path is not None:\n            scheduler.load_state_dict(torch.load(self.path)['scheduler'])\n            \n        return scheduler\n    \n    def get_loss(self, output, target):\n        loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n        loss = loss_fn(output.view(-1, 1), target.view(-1, 1))\n        loss = torch.masked_select(loss, target.view(-1, 1) != -100).mean()\n        return loss","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1644226686042,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"zfNnRUZZG8W5","execution":{"iopub.status.busy":"2022-03-15T11:12:42.974045Z","iopub.execute_input":"2022-03-15T11:12:42.974446Z","iopub.status.idle":"2022-03-15T11:12:42.997472Z","shell.execute_reply.started":"2022-03-15T11:12:42.974412Z","shell.execute_reply":"2022-03-15T11:12:42.996558Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n        self.max = 0\n        self.min = 1e5\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        if val > self.max:\n            self.max = val\n        if val < self.min:\n            self.min = val\n\ndef train_fn(model, train_loader, optimizer, scheduler, device, current_epoch):  \n    losses = AverageMeter()\n    optimizer.zero_grad()\n\n    with tqdm(train_loader, unit=\"batch\") as tepoch:\n        for batch_idx, data in enumerate(tepoch):\n            for k, v in data.items():\n                if k != 'offset_mapping':\n                    data[k] = v.to(config['device'])\n\n            model.train()\n            loss = model(data)['loss'] / config['grad_acc_steps']\n                \n            loss.backward()\n            losses.update(loss.item(), len(train_loader))\n            tepoch.set_postfix(train_loss=losses.avg)\n            \n            if batch_idx % config['grad_acc_steps'] == 0:\n                optimizer.step()\n                scheduler.step()\n                optimizer.zero_grad() \n                \n                if config['report_to'] == 'wandb':\n                    wandb.log({\"epoch\": current_epoch, \"train_loss\": losses.avg, 'lr': scheduler.get_lr()[0]})\n                    \n            \ndef eval_fn(model, valid_loader, device, current_epoch):\n    losses = AverageMeter()\n\n    final_targets = []\n    final_predictions = []\n    offset_mapping = []\n    sequence_ids = []\n\n    model.eval()\n    \n    with torch.no_grad():\n        \n        with tqdm(valid_loader, unit=\"batch\") as tepoch:\n\n            for batch_idx, data in enumerate(tepoch):\n                for k, v in data.items():\n                    if k not in  ['offset_mapping', 'sequence_id']:\n                        data[k] = v.to(config['device'])\n                \n                x = model(data)\n                loss = x['loss']\n                losses.update(loss.item(), len(valid_loader))\n\n                o = x['logits'].detach().cpu().numpy()\n                final_predictions.extend(o)\n                \n                y = data['targets'].detach().cpu().numpy()\n                final_targets.extend(y)\n                \n                offset_mapping.extend(data['offset_mapping'].tolist())\n                sequence_ids.extend(data['sequence_ids'].tolist())\n    \n    predicted_locations = decode_predictions(final_predictions, offset_mapping, sequence_ids, test=False)\n    scores = get_score(predicted_locations, offset_mapping, sequence_ids, final_targets)\n\n    if config['report_to'] == 'wandb':\n        wandb.log({\"epoch\": current_epoch, \"val_loss\": losses.avg, 'val_score': scores['f1']})\n\n    return round(losses.avg, 4), round(scores['f1'], 4)","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644226686042,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"CCGB_IpEDpYL","execution":{"iopub.status.busy":"2022-03-15T11:12:43.000658Z","iopub.execute_input":"2022-03-15T11:12:43.000865Z","iopub.status.idle":"2022-03-15T11:12:43.023465Z","shell.execute_reply.started":"2022-03-15T11:12:43.000841Z","shell.execute_reply":"2022-03-15T11:12:43.022597Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def decode_predictions(preds, offset_mapping, sequence_ids, test=False):\n    \n    all_predictions = []\n    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n        start_idx = None\n        current_preds = []\n        \n        for p, o, s_id in zip(pred, offsets, seq_ids):\n            \n            # do nothing if sequence id is not 1\n            if s_id is None or s_id == 0:\n                continue\n                \n            # if class = 1, track start and end location from offset map\n            if p > 0.5:\n                if start_idx is None:\n                    start_idx = o[0]\n                end_idx = o[1]\n            \n            # if class 0, record previously tracked predictions if not done already\n            elif start_idx is not None:\n                if test:\n                    current_preds.append(f\"{start_idx} {end_idx}\")\n                else:\n                    current_preds.append((start_idx, end_idx))\n                start_idx = None # reset\n                \n        if test:\n            all_predictions.append(\"; \".join(current_preds)) # submission format requirement\n        else:\n            all_predictions.append(current_preds)\n            \n    return all_predictions\n\n\ndef get_score(predictions, offset_mapping, sequence_ids, labels):\n    all_labels = []\n    all_preds = []\n    \n    for preds, offsets, seq_ids, labels in zip(predictions, offset_mapping, sequence_ids, labels):\n        num_chars = max(list(itertools.chain(*offsets)))\n        char_labels = np.zeros((num_chars))\n        \n        # formatting ground truth for evaluation\n        for o, s_id, label in zip(offsets, seq_ids, labels):\n            # do nothing if sequence id is not 1\n            if s_id is None or s_id == 0:\n                continue\n            if int(label) == 1:\n                char_labels[o[0]: o[1]] = 1\n            \n        # formatting predictions for evaluation\n        char_preds = np.zeros((num_chars))\n        for start_idx, end_idx in preds:\n            char_preds[start_idx:end_idx] = 1\n            \n        all_labels.extend(char_labels)\n        all_preds.extend(char_preds)\n        \n    results = metrics.precision_recall_fscore_support(all_labels, all_preds, average = \"binary\")\n    return {\n        \"precision\": results[0],\n        \"recall\": results[1],\n        \"f1\": results[2]\n    }","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644226686043,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"e9Fn7K8UJh0N","execution":{"iopub.status.busy":"2022-03-15T11:12:43.025003Z","iopub.execute_input":"2022-03-15T11:12:43.025420Z","iopub.status.idle":"2022-03-15T11:12:43.040587Z","shell.execute_reply.started":"2022-03-15T11:12:43.025379Z","shell.execute_reply":"2022-03-15T11:12:43.039671Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(model, optimizer, scheduler, epoch, score, best_score, name):\n    print('saving model of this epoch as:', name)\n    \n    name = config['output_dir'] + name\n    torch.save(\n        {\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n            'scheduler': scheduler.state_dict(),\n            'epoch': epoch,\n            'score': score,\n            'best_score': best_score,\n        },\n        name\n    )\n\ndef run(df, fold, tokenizer, device, resume_training_checkpoint=None):\n\n    print('Fold:', fold)\n\n    print('\\npreparing training data...')\n    train_df = df[df['kfold'] != fold].reset_index(drop=True)\n    train_dataset = NBMEData(train_df, tokenizer)\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['train_batch_size'],\n        shuffle=True,\n    )\n    \n    print('\\npreparing validation data...')\n    valid_df = df[df['kfold'] == fold].reset_index(drop=True)\n    valid_dataset = NBMEData(valid_df, tokenizer)\n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size=config['valid_batch_size'],\n        shuffle=False,\n    )\n\n    model = NBMEModel(config['num_labels'], resume_training_checkpoint)\n    model.to(device)\n\n    num_training_steps = (len(train_dataset) // (config['train_batch_size'] * config['grad_acc_steps'])) * config['total_epochs']\n    num_warmup_steps = int(num_training_steps * 0.01)\n    optimizer = model.get_optimizer(config['learning_rate'], config['weight_decay'])\n    scheduler = model.get_scheduler(optimizer, num_warmup_steps, num_training_steps)\n    config['num_training_steps'] =  num_training_steps\n    config['num_warmup_steps'] =  num_warmup_steps \n\n    if config['report_to'] == 'wandb':\n        setup_wandb(config['title'] + '-' + str(fold))\n        wandb.watch(model, log_freq=10)\n\n    epoch_start = 0\n    best_score = -1\n    if resume_training_checkpoint is not None:\n        epoch_start = torch.load(resume_training_checkpoint)['epoch'] + 1\n        best_score = torch.load(resume_training_checkpoint)['best_score']\n    start = time.time()\n\n    for epoch in range(epoch_start, epoch_start + config['epochs_to_train']):   \n\n        print(f'\\n\\n\\nTraining Epoch: {epoch}')\n        train_fn(model, train_loader, optimizer, scheduler, device, epoch)\n        \n        print('Evaluation...')\n        val_loss, val_score = eval_fn(\n            model=model, \n            valid_loader=valid_loader, \n            device=device,\n            current_epoch=epoch,\n        )\n        \n        if val_score > best_score:\n            best_score = val_score\n            save_checkpoint(model, optimizer, scheduler, epoch, val_score, best_score, f'best_model_{fold}.bin')\n\n        save_checkpoint(model, optimizer, scheduler, epoch, val_score, best_score, f'last_model_{fold}.bin')\n\n        print('Valid Score:', val_score, 'Valid Loss:', val_loss, 'Best Score:', best_score)\n        \n    print(f'Best Score: {best_score}, Time Taken: {round(time.time() - start, 4)}s')\n    print()\n    \n    if config['report_to'] == 'wandb':    \n        wandb.finish()","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644226686043,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"WEl0sAVqrSwn","execution":{"iopub.status.busy":"2022-03-15T11:12:43.042362Z","iopub.execute_input":"2022-03-15T11:12:43.042631Z","iopub.status.idle":"2022-03-15T11:12:43.064771Z","shell.execute_reply.started":"2022-03-15T11:12:43.042597Z","shell.execute_reply":"2022-03-15T11:12:43.063912Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(config['tokenizer_path'])","metadata":{"executionInfo":{"elapsed":5352,"status":"ok","timestamp":1644226691388,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"aDSl8OtJtMZ2","outputId":"88ece67b-6dc0-4714-c2b0-6617eb626e54","execution":{"iopub.status.busy":"2022-03-15T11:12:43.066366Z","iopub.execute_input":"2022-03-15T11:12:43.067022Z","iopub.status.idle":"2022-03-15T11:12:48.423803Z","shell.execute_reply.started":"2022-03-15T11:12:43.066983Z","shell.execute_reply":"2022-03-15T11:12:48.422966Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train = spark.read.parquet(\"../input/nbme-convert-to-parquet-files/train.parquet\", header=True, inferSchema=True).toPandas() # pd.read_csv('../input/nbme-cleaned-with-extra-data-and-folds/train.csv')\nnotes = spark.read.parquet(\"../input/nbme-convert-to-parquet-files/patient_notes.parquet\", header=True, inferSchema=True).toPandas() # pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\nfeats = spark.read.parquet(\"../input/nbme-convert-to-parquet-files/features.parquet\", header=True, inferSchema=True).toPandas() # pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\n\ntrain_ids = set(train.id.tolist())\n\n# df_pseudo_label = pd.read_csv(\n#     '../input/deberta-v3-large-0-883-lb-pseudo-label/submission.csv'\n# )\n\ndf_pseudo_label = spark.read.parquet(\n    '../input/nbme-convert-to-parquet-files/pseudo_label.parquet',\n    header=True, inferSchema=True\n).toPandas()\n\ndf_pseudo_label = df_pseudo_label.query(\"id not in @train_ids\")\ndf_pseudo_label, _ = model_selection.train_test_split(\n    df_pseudo_label,\n    test_size=0.6,\n    stratify=df_pseudo_label['feature_num'].astype(str) + '_' + df_pseudo_label['case_num'].astype(str),\n    random_state=config['seed'],\n)\ndf_pseudo_label['kfold'] = -1\ndf_pseudo_label.drop(['pn_history', 'feature_text'], axis=1)\ndf_pseudo_label = df_pseudo_label.merge(notes, how = \"left\")\ndf_pseudo_label = df_pseudo_label.merge(feats, how = \"left\")\n\ntrain = pd.concat([train, df_pseudo_label]).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:12:48.425543Z","iopub.execute_input":"2022-03-15T11:12:48.426113Z","iopub.status.idle":"2022-03-15T11:13:00.694796Z","shell.execute_reply.started":"2022-03-15T11:12:48.426070Z","shell.execute_reply":"2022-03-15T11:13:00.694034Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"df_pseudo_label.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:13:00.695925Z","iopub.execute_input":"2022-03-15T11:13:00.696677Z","iopub.status.idle":"2022-03-15T11:13:00.715153Z","shell.execute_reply.started":"2022-03-15T11:13:00.696638Z","shell.execute_reply":"2022-03-15T11:13:00.714527Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"          id  case_num  pn_num  feature_num  kfold  \\\n0  43206_402         4   43206          402     -1   \n1  91478_913         9   91478          913     -1   \n2  92252_915         9   92252          915     -1   \n3  70785_700         7   70785          700     -1   \n4  31503_314         3   31503          314     -1   \n\n                               feature_text  \\\n0  Stress-due-to-caring-for-elderly-parents   \n1                                    Female   \n2                 No-known-illness-contacts   \n3                                    Female   \n4                                    Nausea   \n\n                                          pn_history     location  \n0  45 y o f  C/O EPISODES OF NERVOUSNESS IRRESPEC...  ['142 179']  \n1  HPI: 20Y/O, F, C/O HEADACHE X 24 HRS, SUDDEN, ...    ['12 13']  \n2  20 YO F, with history of migraine HA, comes to...           []  \n3  35 yo F presents with heavy menstrual bleeding...      ['6 7']  \n4  Chad Hamilton, 35 yo\\r\\nPresents with epigastr...  ['230 236']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>case_num</th>\n      <th>pn_num</th>\n      <th>feature_num</th>\n      <th>kfold</th>\n      <th>feature_text</th>\n      <th>pn_history</th>\n      <th>location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>43206_402</td>\n      <td>4</td>\n      <td>43206</td>\n      <td>402</td>\n      <td>-1</td>\n      <td>Stress-due-to-caring-for-elderly-parents</td>\n      <td>45 y o f  C/O EPISODES OF NERVOUSNESS IRRESPEC...</td>\n      <td>['142 179']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>91478_913</td>\n      <td>9</td>\n      <td>91478</td>\n      <td>913</td>\n      <td>-1</td>\n      <td>Female</td>\n      <td>HPI: 20Y/O, F, C/O HEADACHE X 24 HRS, SUDDEN, ...</td>\n      <td>['12 13']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>92252_915</td>\n      <td>9</td>\n      <td>92252</td>\n      <td>915</td>\n      <td>-1</td>\n      <td>No-known-illness-contacts</td>\n      <td>20 YO F, with history of migraine HA, comes to...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70785_700</td>\n      <td>7</td>\n      <td>70785</td>\n      <td>700</td>\n      <td>-1</td>\n      <td>Female</td>\n      <td>35 yo F presents with heavy menstrual bleeding...</td>\n      <td>['6 7']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>31503_314</td>\n      <td>3</td>\n      <td>31503</td>\n      <td>314</td>\n      <td>-1</td>\n      <td>Nausea</td>\n      <td>Chad Hamilton, 35 yo\\r\\nPresents with epigastr...</td>\n      <td>['230 236']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.id.nunique() == train.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:13:00.716186Z","iopub.execute_input":"2022-03-15T11:13:00.716586Z","iopub.status.idle":"2022-03-15T11:13:00.735924Z","shell.execute_reply.started":"2022-03-15T11:13:00.716550Z","shell.execute_reply":"2022-03-15T11:13:00.735312Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# train['annotation'] = train['annotation'].apply(ast.literal_eval)\ntrain['location'] = train['location'].apply(ast.literal_eval)","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:13:00.737324Z","iopub.execute_input":"2022-03-15T11:13:00.737653Z","iopub.status.idle":"2022-03-15T11:13:01.195209Z","shell.execute_reply.started":"2022-03-15T11:13:00.737609Z","shell.execute_reply":"2022-03-15T11:13:01.194472Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"if config['debug']:\n    train = train.sample(config['debug']).reset_index(drop=True)","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1644226694327,"user":{"displayName":"Manan Jhaveri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFSj0LIjInPPaaILFTu8Yb1mJR7ve0H4z3bFJeaA=s64","userId":"08247634115223416888"},"user_tz":-330},"id":"fXVGb0LNchml","execution":{"iopub.status.busy":"2022-03-15T11:13:01.196370Z","iopub.execute_input":"2022-03-15T11:13:01.196665Z","iopub.status.idle":"2022-03-15T11:13:01.201259Z","shell.execute_reply.started":"2022-03-15T11:13:01.196621Z","shell.execute_reply":"2022-03-15T11:13:01.200389Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:13:01.202572Z","iopub.execute_input":"2022-03-15T11:13:01.203015Z","iopub.status.idle":"2022-03-15T11:13:01.213403Z","shell.execute_reply.started":"2022-03-15T11:13:01.202977Z","shell.execute_reply":"2022-03-15T11:13:01.212700Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(38859, 9)"},"metadata":{}}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:13:01.215825Z","iopub.execute_input":"2022-03-15T11:13:01.216132Z","iopub.status.idle":"2022-03-15T11:13:01.231533Z","shell.execute_reply.started":"2022-03-15T11:13:01.216090Z","shell.execute_reply":"2022-03-15T11:13:01.230677Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"          id  case_num  pn_num  feature_num  \\\n0  00016_000         0      16            0   \n1  00016_001         0      16            1   \n2  00016_002         0      16            2   \n3  00016_003         0      16            3   \n4  00016_004         0      16            4   \n\n                                 annotation          location  kfold  \\\n0          ['dad with recent heart attcak']         [696 724]    NaN   \n1             ['mom with \"thyroid disease']         [668 693]    NaN   \n2                        ['chest pressure']         [203 217]    NaN   \n3      ['intermittent episodes', 'episode']  [70 91, 176 183]    NaN   \n4  ['felt as if he were going to pass out']         [222 258]    NaN   \n\n  feature_text pn_history  \n0          NaN        NaN  \n1          NaN        NaN  \n2          NaN        NaN  \n3          NaN        NaN  \n4          NaN        NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>case_num</th>\n      <th>pn_num</th>\n      <th>feature_num</th>\n      <th>annotation</th>\n      <th>location</th>\n      <th>kfold</th>\n      <th>feature_text</th>\n      <th>pn_history</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00016_000</td>\n      <td>0</td>\n      <td>16</td>\n      <td>0</td>\n      <td>['dad with recent heart attcak']</td>\n      <td>[696 724]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00016_001</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>['mom with \"thyroid disease']</td>\n      <td>[668 693]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00016_002</td>\n      <td>0</td>\n      <td>16</td>\n      <td>2</td>\n      <td>['chest pressure']</td>\n      <td>[203 217]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00016_003</td>\n      <td>0</td>\n      <td>16</td>\n      <td>3</td>\n      <td>['intermittent episodes', 'episode']</td>\n      <td>[70 91, 176 183]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00016_004</td>\n      <td>0</td>\n      <td>16</td>\n      <td>4</td>\n      <td>['felt as if he were going to pass out']</td>\n      <td>[222 258]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.kfold.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T11:13:01.232711Z","iopub.execute_input":"2022-03-15T11:13:01.233097Z","iopub.status.idle":"2022-03-15T11:13:01.246224Z","shell.execute_reply.started":"2022-03-15T11:13:01.233063Z","shell.execute_reply":"2022-03-15T11:13:01.245528Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"-1.0    24559\nName: kfold, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"if not config['inference_only']:\n    for fold in config['fold_to_train']:\n        run(\n            df=train, \n            fold=fold,\n            tokenizer=tokenizer,\n            device=config['device'],\n            resume_training_checkpoint=config['resume_training_checkpoint'],\n        )\n        torch.cuda.empty_cache()\n        gc.collect()","metadata":{"id":"yH4NO9GeCV-i","outputId":"e4e5c9f0-5cbe-4755-ec09-53464d214172","execution":{"iopub.status.busy":"2022-03-15T11:13:01.247521Z","iopub.execute_input":"2022-03-15T11:13:01.247818Z","iopub.status.idle":"2022-03-15T11:13:22.466475Z","shell.execute_reply.started":"2022-03-15T11:13:01.247784Z","shell.execute_reply":"2022-03-15T11:13:22.465354Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Fold: 4\n\npreparing training data...\n\npreparing validation data...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at ../input/robertalarge were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBackendError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3145115207.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mresume_training_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resume_training_checkpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         )\n\u001b[1;32m     10\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/166829344.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(df, fold, tokenizer, device, resume_training_checkpoint)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'report_to'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'wandb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msetup_wandb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3398865780.py\u001b[0m in \u001b[0;36msetup_wandb\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle_secrets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUserSecretsClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0muser_secrets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUserSecretsClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msecret_value_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_secrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_secret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wandb_api_key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msecret_value_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.7/site-packages/kaggle_secrets.py\u001b[0m in \u001b[0;36mget_secret\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;34m'Label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         }\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mresponse_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweb_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_post_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_USER_SECRET_BY_LABEL_ENDPOINT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'secret'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise BackendError(\n","\u001b[0;32m~/.local/lib/python3.7/site-packages/kaggle_web_client.py\u001b[0m in \u001b[0;36mmake_post_request\u001b[0;34m(self, data, endpoint, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wasSuccessful'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'result'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     raise BackendError(\n\u001b[0;32m---> 50\u001b[0;31m                         f'Unexpected response from the service. Response: {response_json}.')\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBackendError\u001b[0m: Unexpected response from the service. Response: {'errors': ['No user secrets exist for kernel id 25373538 and label wandb_api_key.'], 'error': {'code': 5, 'details': []}, 'wasSuccessful': False}."],"ename":"BackendError","evalue":"Unexpected response from the service. Response: {'errors': ['No user secrets exist for kernel id 25373538 and label wandb_api_key.'], 'error': {'code': 5, 'details': []}, 'wasSuccessful': False}.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}